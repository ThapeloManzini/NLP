{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti-wmKoaw9xm"
      },
      "source": [
        "## **Problem Statement**\n",
        "## **Text Analysis and Natural Language Processing (NLP)**\n",
        "\n",
        "## This project is designed to introduce students to the fundamental concepts and practical applications of Text Analysis and Natural Language Processing (NLP), two key areas in the field of Data Science and Artificial Intelligence. The focus of this project is on processing and analyzing text data from the classic novel \"Alice's Adventures in Wonderland\" by Lewis Carroll.\n",
        "\n",
        "## **Why Text Analysis and NLP?**\n",
        "## Text Analysis and NLP involves the use of computational techniques to understand, interpret, and generate human language. These techniques are essential in various applications such as search engines, sentiment analysis, machine translation, chatbots, and more. By analyzing text data, we can extract meaningful insights, automate tasks like categorization, and develop models that can interact with human language in intelligent ways."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOsST-XEMP2V"
      },
      "source": [
        "### Import Libraries and Read In the Data\n",
        "\n",
        "### **Do not modify or remove any of the code in these cells.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqTThz4YMP2W"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "# Tokenization and stemming (you can choose a language as compared to Porter stemmer)\n",
        "from nltk import TreebankWordTokenizer, SnowballStemmer\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer #lemmatization\n",
        "from nltk.corpus import stopwords\n",
        "import string #we use this module to convert the 'case' of the text\n",
        "import urllib #used to handle URL: in this instance we fetch our .txt)\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gznMWT7ASwD",
        "outputId": "2ae1dff9-e668-4614-9e58-758cba391e21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alice's Adventures in Wonderland\n",
            "\n",
            "                ALICE'S ADVENTURES IN WONDERLAND\n",
            "\n",
            "                          Lewis Carroll\n",
            "\n",
            "               THE MILLENNIUM FULCRUM EDITION 3.0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "                            CHAPTER I\n",
            "\n",
            "                      Down the Rabbit-Hole\n",
            "\n",
            "\n",
            "  Alice was beginning to get very tired of sitting by her sister\n",
            "on the bank, and of having nothing to do:  once or twice she had\n",
            "peeped into the book her sister was reading, but it had no\n",
            "pictures or conversations in it, `and what is the use of a book,'\n",
            "thought Alice `without pictures or conversation?'\n",
            "\n",
            "  So she was considering in her own mind (as well as she could,\n",
            "for the hot day made her feel very sleepy and stupid), whether\n",
            "the pleasure of making a daisy-chain would be worth the trouble\n",
            "of getting up and picking the daisies, when suddenly a White\n",
            "Rabbit with pink eyes ran close by her.\n",
            "\n",
            " \n"
          ]
        }
      ],
      "source": [
        "# Define a function to read from a local .txt file\n",
        "def read_local_file(file_path):\n",
        "    with open(file_path, 'r', encoding='ISO-8859-1') as f:\n",
        "        return f.read()\n",
        "\n",
        "# Specify the path to your local text file\n",
        "file_path = 'alice_in_wonderland.txt'\n",
        "\n",
        "# Read the file and print the first 863 characters\n",
        "data = read_local_file(file_path)\n",
        "print(data[:863])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4ESVxdZMP2Y"
      },
      "source": [
        "### Convert to lowercase and remove punctuation  \n",
        "\n",
        "### **Do not change or remove any of the code in these cells**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irDw3igFMP2Z"
      },
      "outputs": [],
      "source": [
        "def remove_punctuation(words):\n",
        "    words = words.lower()\n",
        "    return ''.join([x for x in words if x not in string.punctuation])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2EP4mUtMP2Z"
      },
      "outputs": [],
      "source": [
        "data = remove_punctuation(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QOX0wRQMP2a"
      },
      "source": [
        "### Creating a bag of words and assigning our stemmer and lemmatizer\n",
        "\n",
        "### **Pay special attention to what these functions return and how the subsequent texts and lists look**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6bvJyV3MP2b"
      },
      "outputs": [],
      "source": [
        "# define stemmer function\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "# tokenise data\n",
        "tokeniser = TreebankWordTokenizer()\n",
        "tokens = tokeniser.tokenize(data)\n",
        "\n",
        "# define lemmatiser\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# bag of words\n",
        "def bag_of_words_count(words, word_dict={}):\n",
        "    \"\"\" this function takes in a list of words and returns a dictionary\n",
        "        with each word as a key, and the value represents the number of\n",
        "        times that word appeared\"\"\"\n",
        "    for word in words:\n",
        "        if word in word_dict.keys():\n",
        "            word_dict[word] += 1\n",
        "        else:\n",
        "            word_dict[word] = 1\n",
        "    return word_dict\n",
        "\n",
        "# remove stopwords\n",
        "tokens_less_stopwords = [word for word in tokens if word not in stopwords.words('english')]\n",
        "\n",
        "# create bag of words\n",
        "bag_of_words = bag_of_words_count(tokens_less_stopwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfIJWmrUMP2c"
      },
      "source": [
        "## **Question 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UsHi8WnMP2d"
      },
      "source": [
        "Use the stemmer and lemmatizer functions (defined in the cells above) from the relevant library to find the stem and lemma of the nth word in the token list.\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Should take a `list` as input and return a  `dict` type as output.\n",
        "* The dictionary should have the keys **'original',  'stem' and 'lemma'** with the corresponding values being the nth word transformed in that way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvafIUwFMP2d"
      },
      "outputs": [],
      "source": [
        "### START FUNCTION\n",
        "\n",
        "def find_roots(token_list, n):\n",
        "    # your code here\n",
        "\n",
        "    return\n",
        "\n",
        "### END FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-RJyEzcvMP2e",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "find_roots(tokens, 120)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNDbtiLpMP2e"
      },
      "source": [
        "_**Expected Outputs:**_\n",
        "```python\n",
        "find_roots(tokens, 80) ==\n",
        "{'original': 'Alice',\n",
        "'stem': 'alic',\n",
        "'lemma': 'alice'}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g6a23qLMP2e"
      },
      "source": [
        "## **Question 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq7Qf089MP2f"
      },
      "source": [
        "How many stopwords are in the text in total?   \n",
        "\n",
        "_Hint_ : you can use the nltk stopwords dictionary\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Function should take a `list` as input\n",
        "* The number of stopwords should be returned as an `int`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZP83iq-JMP2g"
      },
      "outputs": [],
      "source": [
        "### START FUNCTION\n",
        "def count_stopwords(token_list):\n",
        "    # your code here\n",
        "\n",
        "\n",
        "### END FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrjfyqWPMP2g"
      },
      "outputs": [],
      "source": [
        "count_stopwords(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kY2SeexuMP2h"
      },
      "source": [
        "_**Expected output:**_\n",
        "\n",
        "```python\n",
        "count_stopwords(tokens) == 12286\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwxC3-nvMP2h"
      },
      "source": [
        "## **Question 3**\n",
        "\n",
        "You have been provided with a list of words (tokens) extracted from a text document. Your task is to identify how many unique words are present in this list. Write a Python function called unique_words that accepts the list of tokens as input and returns the total count of unique words in the list.\n",
        "\n",
        "    Hint: You may use a data structure that automatically removes duplicate entries to help you find the number of unique words.\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Function should take a `list` as input and return an `int`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRO6ceGEMP2h"
      },
      "outputs": [],
      "source": [
        "### START FUNCTION\n",
        "def unique_words(token_list):\n",
        "    # your code here\n",
        "\n",
        "### END FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMPgo15sMP2h"
      },
      "outputs": [],
      "source": [
        "unique_words(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3GlAnfkMP2i"
      },
      "source": [
        "_**Expected output:**_\n",
        "\n",
        "```python\n",
        "unique_words(tokens) == 3628\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qa_Kc897MP2i"
      },
      "source": [
        "## **Question 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzUPLwR3MP2i"
      },
      "source": [
        "You have been provided with a dictionary where the keys are words, and the values represent the frequency of each word's occurrence in a text. Your task is to write a Python function called most_common_word that takes this dictionary and an integer k as inputs. The function should return the kth most frequently occurring word in the text.\n",
        "\n",
        "    Hint: You will need to sort the dictionary by the frequency of the words in descending order to find the kth most common word.\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Function should take a `dict` and an `int` k as input\n",
        "* Function should return the kth most common word as a `str`\n",
        "\n",
        "Example:\n",
        "\n",
        "bag_of_words = {'alice': 15, 'rabbit': 10, 'little': 8, 'queen': 5, 'wonderland': 12} and k=2,\n",
        "\n",
        "the function should return  **wonderland**, as it is the second most frequent word in the text.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lucp3ulKMP2i"
      },
      "outputs": [],
      "source": [
        "### START FUNCTION\n",
        "def most_common_word(bag, k):\n",
        "    # your code here\n",
        "\n",
        "    return\n",
        "\n",
        "### END FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEXA5KdsMP2j"
      },
      "outputs": [],
      "source": [
        "most_common_word(bag_of_words, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUxpxXoaMP2j"
      },
      "source": [
        "_**Expected output:**_\n",
        "\n",
        "```python\n",
        "most_common_word(bag_of_words, 6) == 'Alice'\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-91H10KMP2j"
      },
      "source": [
        "## **Question 5**\n",
        "\n",
        "How many words appear n times in the text?\n",
        "\n",
        "_**Function Specifications:**_\n",
        "* Input is taken as a `dict` and an `int` n, where n is the number of times the word appears in the text\n",
        "* Count the number of words that appear n times in the text\n",
        "* Output should be the count as an `int`\n",
        "\n",
        "Example:\n",
        "```python\n",
        "For the dictionary bag_of_words = {'alice': 15, 'rabbit': 10, 'little': 8,\n",
        "\n",
        "'queen': 5, 'wonderland': 12, 'hat': 5, 'cat': 5, 'mouse': 8, 'mad': 8, 'tea': 5} and n=5,\n",
        "\n",
        "the function should return 4, because there are four words that appear exactly 5 times in the text\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7ZAClVRMP2j"
      },
      "outputs": [],
      "source": [
        "### START FUNCTION\n",
        "\n",
        "def word_frequency_count(bag, n):\n",
        "    # your code here\n",
        "    return\n",
        "### END FUNCTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIiHpF78MP2k"
      },
      "outputs": [],
      "source": [
        "word_frequency_count(bag_of_words, 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yED5hZZ1MP2k"
      },
      "outputs": [],
      "source": [
        "word_frequency_count(bag_of_words, 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgn6Xh6bMP2k"
      },
      "source": [
        "_**Expected output:**_\n",
        "\n",
        "```python\n",
        "word_frequency_count(bag_of_words, 5) == 116\n",
        "word_frequency_count(bag_of_words, 8) == 55\n",
        "\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
